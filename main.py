import os
import random
import time
import requests
import json
from bs4 import BeautifulSoup
from requests.auth import HTTPBasicAuth

# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')
WP_USERNAME = os.environ.get('WP_USERNAME')
WP_APP_PASSWORD = os.environ.get('WP_APP_PASSWORD')
WP_BASE_URL = "https://virz.net" 

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„¤ì • (Trueë©´ 1ê°œë§Œ ì¦‰ì‹œ ë°œí–‰, Falseë©´ 10ê°œ ëœë¤ ë°œí–‰)
# ê¹ƒí—ˆë¸Œ ì‹œí¬ë¦¿ì— TEST_MODEë¥¼ trueë¡œ ì„¤ì •í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ ì§ì ‘ Trueë¡œ ë°”ê¿”ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.
IS_TEST = os.environ.get('TEST_MODE', 'false').lower() == 'true'

class NaverScraper:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ë° ë¸”ë¡œê·¸ ë­í‚¹ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        }

    def get_news_ranking(self, section_id):
        url = f"https://news.naver.com/main/ranking/popularDay.naver?sectionId={section_id}"
        try:
            res = requests.get(url, headers=self.headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            titles = soup.select(".rankingnews_list .list_title")
            return [t.text.strip() for t in titles[:10]]
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ({section_id}): {e}", flush=True)
            return []

    def get_blog_hot_topics(self):
        url = "https://section.blog.naver.com/HotTopicList.naver"
        try:
            res = requests.get(url, headers=self.headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            topics = soup.select(".list_hottopic .desc")
            return [topic.text.strip() for topic in topics[:10]]
        except Exception as e:
            print(f"ë¸”ë¡œê·¸ í•«í† í”½ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}", flush=True)
            return []

def expand_title(keyword, category):
    """í‚¤ì›Œë“œë¥¼ ë§¤ë ¥ì ì¸ ë¡±í…Œì¼ ì œëª©ìœ¼ë¡œ í™•ì¥"""
    data = {
        "ê²½ì œ/ë¹„ì¦ˆë‹ˆìŠ¤": {
            "targets": ["ì§ì¥ì¸", "ì¬í…Œí¬ì¡±", "ì‚¬íšŒì´ˆë…„ìƒ"],
            "scenarios": ["ì‹¤ì§ˆì ì¸ ë³€í™”", "2026ë…„ ì •ì±… ë¶„ì„", "ë†“ì¹˜ë©´ ì•ˆ ë  í˜œíƒ"],
            "suffixes": ["ê°€ì´ë“œ", "í•µì‹¬ ìš”ì•½", "ì£¼ì˜ì‚¬í•­"]
        },
        "IT/í…Œí¬": {
            "targets": ["ì–¼ë¦¬ì–´ë‹µí„°", "IT ì¢…ì‚¬ì", "í•™ìƒ"],
            "scenarios": ["ì‚¬ìš© í›„ê¸°", "ìŠ¤í™ ë¹„êµ", "í• ì¸ ê¿€íŒ"],
            "suffixes": ["ì™„ë²½ ê°€ì´ë“œ", "ì¶”ì²œ ë¦¬ìŠ¤íŠ¸", "ì†”ì§ ë¦¬ë·°"]
        },
        "íŒ¨ì…˜/ë·°í‹°/ë¦¬ë¹™": {
            "targets": ["íŒ¨ì…˜ í”¼í”Œ", "ê·¸ë£¨ë°ì¡±", "ìì·¨ìƒ", "ì‹ í˜¼ë¶€ë¶€"],
            "scenarios": ["ì˜¬í•´ ìœ í–‰ ìŠ¤íƒ€ì¼", "ê°€ì„±ë¹„ ì¶”ì²œí…œ", "ê³µê°„ í™œìš©ë²•"],
            "suffixes": ["ì½”ë”” ì œì•ˆ", "íŠ¸ë Œë“œ ë¦¬í¬íŠ¸", "ê¿€í…œ ë¦¬ë·°"]
        }
    }.get(category, {
        "targets": ["ëˆ„êµ¬ë‚˜", "ê´€ì‹¬ ìˆëŠ” ë¶„ë“¤"],
        "scenarios": ["ì•Œì•„ì•¼ í•  ì •ë³´", "ìµœì‹  ì†Œì‹"],
        "suffixes": ["ì •ë¦¬", "ê·¼í™©"]
    })

    t, s, sx = random.choice(data["targets"]), random.choice(data["scenarios"]), random.choice(data["suffixes"])
    templates = [
        f"[{t} í•„ë…] {keyword} {s} {sx}",
        f"{keyword} {s}, {t}ì´ ê¼­ ì•Œì•„ì•¼ í•  {sx}",
        f"{t}ì„ ìœ„í•œ {keyword} {sx}: {s} í¬í•¨"
    ]
    return random.choice(templates)

def generate_content(title, category):
    """Gemini APIë¥¼ ì´ìš©í•œ ë³¸ë¬¸ ìƒì„± (gemini-2.5-flash-preview-09-2025)"""
    model_id = "gemini-2.5-flash-preview-09-2025"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_id}:generateContent?key={GEMINI_API_KEY}"
    
    system_prompt = f"ë‹¹ì‹ ì€ {category} ë¶„ì•¼ ì „ë¬¸ ë¸”ë¡œê±°ì…ë‹ˆë‹¤. virz.net ë¸”ë¡œê·¸ì— ì˜¬ë¦´ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”."
    user_query = f"""
    ì œëª©: {title}
    
    [ì‘ì„± ê°€ì´ë“œë¼ì¸]
    1. ì„œë¡ : ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ë„ì…ë¶€.
    2. ë³¸ë¡ : 3ê°œì˜ í•µì‹¬ ì†Œì£¼ì œ(H2 í—¤ë”© ì‚¬ìš©)ë¡œ ìƒì„¸ ì„¤ëª….
    3. í‘œ: ë°ì´í„°ë‚˜ íŠ¹ì§•ì„ ë¹„êµí•˜ëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¥¼ ë°˜ë“œì‹œ 1ê°œ í¬í•¨.
    4. ê²°ë¡ : ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ë…ìì—ê²Œ ë§ˆì§€ë§‰ ì¡°ì–¸.
    5. ë§íˆ¬: ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ êµ¬ì–´ì²´ (~í•´ìš”).
    6. í˜•ì‹: HTML íƒœê·¸(h2, p, table, tr, td ë“±)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„± (ë§ˆí¬ë‹¤ìš´ì´ ì•„ë‹Œ HTMLë¡œ ì¶œë ¥).
    
    ì£¼ì˜: "AIë¡œì„œ ì‘ì„±í•œ ê¸€ì…ë‹ˆë‹¤"ì™€ ê°™ì€ ë¬¸êµ¬ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    """
    
    payload = {
        "contents": [{"parts": [{"text": user_query}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]}
    }
    
    delays = [1, 2, 4, 8, 16]
    for delay in delays:
        try:
            response = requests.post(url, json=payload, timeout=60)
            if response.status_code == 200:
                result = response.json()
                text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text')
                if text: return text
            elif response.status_code in [429, 500, 502, 503, 504]:
                time.sleep(delay)
                continue
            else:
                print(f"API ì˜¤ë¥˜: {response.status_code} - {response.text}", flush=True)
                break
        except Exception as e:
            print(f"API ì—°ê²° ì˜ˆì™¸ ë°œìƒ: {e}", flush=True)
            time.sleep(delay)
            continue
    return None

def post_to_wp(title, content):
    """ì›Œë“œí”„ë ˆìŠ¤ REST API ì—…ë¡œë“œ"""
    url = f"{WP_BASE_URL}/wp-json/wp/v2/posts"
    payload = {
        "title": title,
        "content": content,
        "status": "publish"
    }
    try:
        res = requests.post(
            url,
            auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD),
            json=payload,
            timeout=30
        )
        return res.status_code == 201
    except Exception as e:
        print(f"ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}", flush=True)
        return False

def main():
    scraper = NaverScraper()
    print("ğŸš€ [1ë‹¨ê³„] í‚¤ì›Œë“œ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...", flush=True)
    
    jobs = [
        ("101", "ê²½ì œ/ë¹„ì¦ˆë‹ˆìŠ¤"),
        ("105", "IT/í…Œí¬"),
        ("103", "íŒ¨ì…˜/ë·°í‹°/ë¦¬ë¹™"),
        (None, "ì¼ë°˜/ìƒí™œ")
    ]
    
    candidates = []
    for sid, cat in jobs:
        titles = scraper.get_news_ranking(sid) if sid else scraper.get_blog_hot_topics()
        for t in titles[:5]:
            candidates.append({"kw": t, "cat": cat})
        time.sleep(1)

    if not candidates:
        print("âŒ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œê°€ ì—†ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.", flush=True)
        return
        
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€ì— ë”°ë¥¸ ê°œìˆ˜ ë° ëŒ€ê¸° ì‹œê°„ ì„¤ì •
    if IS_TEST:
        print("\nğŸ§ª [í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”] 1ê°œì˜ í¬ìŠ¤íŒ…ì„ ì¦‰ì‹œ ë°œí–‰í•©ë‹ˆë‹¤.", flush=True)
        selected = random.sample(candidates, 1)
        posting_times = [0] # ì¦‰ì‹œ ì‹¤í–‰
    else:
        selected = random.sample(candidates, min(len(candidates), 10))
        print(f"\nğŸ“… [2ë‹¨ê³„] ì˜¤ëŠ˜ ë°œí–‰í•  {len(selected)}ê°œì˜ ê¸€ê°ì„ ì„ ì •í–ˆìŠµë‹ˆë‹¤.", flush=True)
        # 2ì‹œê°„(7200ì´ˆ) ë²”ìœ„ ë‚´ ë¬´ì‘ìœ„ ë°œí–‰ ì‹œê°„ ê³„ì‚°
        total_seconds = 2 * 60 * 60
        posting_times = sorted([random.randint(0, total_seconds) for _ in range(len(selected))])
        
        print(f"â° ì „ì²´ ë°œí–‰ ì˜ˆì • ì¼ì • (í˜„ì¬ ì‹œì  ê¸°ì¤€):", flush=True)
        for i, pt in enumerate(posting_times):
            print(f" - {i+1}ë²ˆ í¬ìŠ¤íŒ…: ì•½ {pt//60}ë¶„ ë’¤", flush=True)

    last_wait = 0
    for i, item in enumerate(selected):
        wait_for_next = posting_times[i] - last_wait
        if wait_for_next > 0:
            print(f"\nâ³ [{i+1}/{len(selected)}] ë‹¤ìŒ ë°œí–‰ê¹Œì§€ ì•½ {wait_for_next//60}ë¶„ {wait_for_next%60}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤...", flush=True)
            time.sleep(wait_for_next)
        
        final_title = expand_title(item['kw'], item['cat'])
        print(f"ğŸ“ ë³¸ë¬¸ ìƒì„± ì‹œì‘: {final_title}", flush=True)
        body = generate_content(final_title, item['cat'])
        
        if body:
            if post_to_wp(final_title, body):
                print(f"âœ… ë°œí–‰ ì™„ë£Œ: {final_title}", flush=True)
            else:
                print(f"âŒ ì›Œë“œí”„ë ˆìŠ¤ ì „ì†¡ ì‹¤íŒ¨: {final_title}", flush=True)
        else:
            print(f"âŒ AI ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨: {final_title}", flush=True)
            
        last_wait = posting_times[i]

    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    main()
